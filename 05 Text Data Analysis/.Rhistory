library(tm)
library(wordcloud)
library(plyr)
library(igraph)
# Load the dataset
ObamaSpeech <- read.csv("speechBylineTable_utf8.csv", stringsAsFactors = FALSE)
# Select the first five speeches
idx1 <- which(ObamaSpeech$idx <= 5)
Speech1 <-as.data.frame(ObamaSpeech$contents[idx1])
names(Speech1) <- "sentence"
# Select the last five speeches
idx2 <- which(ObamaSpeech$idx > 97)
Speech2 <-as.data.frame(ObamaSpeech$contents[idx2])
names(Speech2) <- "sentence"
# Construct a corpus
# VectorSource specifies that the source is character vectors.
myCorpus1 <- Corpus(VectorSource(Speech1$sentence))
myCorpus1[[1]][1]
myCorpus2 <- Corpus(VectorSource(Speech2$sentence))
myCorpus2[[1]][1]
# Data preprocessing
# 1: to lower case
myCorpus1 <- tm_map(myCorpus1, content_transformer(tolower))
myCorpus1[[1]][1]
myCorpus2 <- tm_map(myCorpus2, content_transformer(tolower))
myCorpus2[[1]][1]
# 2: remove puntuations
myCorpus1 <- tm_map(myCorpus1, content_transformer(removePunctuation))
myCorpus1[[1]][1]
myCorpus2 <- tm_map(myCorpus2, content_transformer(removePunctuation))
myCorpus2[[1]][1]
# 3. remove numbers
myCorpus1 <- tm_map(myCorpus1, content_transformer(removeNumbers))
myCorpus1[[1]][1]
myCorpus2 <- tm_map(myCorpus2, content_transformer(removeNumbers))
myCorpus2[[1]][1]
# 4. remove stopwords (SMART stopwords list)
# Add "obama" to the stopwords list
myStopwords <- c(stopwords("SMART"), "obama")
myCorpus1 <- tm_map(myCorpus1, removeWords, myStopwords)
myCorpus1[[1]][1]
myCorpus2 <- tm_map(myCorpus2, removeWords, myStopwords)
myCorpus2[[1]][1]
# 5. Stemming
stemCorpus1 <- tm_map(myCorpus1, stemDocument)
myCorpus1[[1]][1]
stemCorpus2 <- tm_map(myCorpus2, stemDocument)
myCorpus2[[1]][1]
# Construct Term-Document Matrix
myTDM1 <- TermDocumentMatrix(stemCorpus1, control = list(minWordLength = 1))
myTDM2 <- TermDocumentMatrix(stemCorpus2, control = list(minWordLength = 1))
# Check the Term-Document Matrix
myTDM1
myTDM2
setwd("D:/Dropbox/Github/R-for-Data-Analytics/05 Text Data Analysis")
library(tm)
library(wordcloud)
library(plyr)
library(igraph)
# Load the dataset
ObamaSpeech <- read.csv("speechBylineTable_utf8.csv", stringsAsFactors = FALSE)
# Select the first five speeches
idx1 <- which(ObamaSpeech$idx <= 5)
Speech1 <-as.data.frame(ObamaSpeech$contents[idx1])
names(Speech1) <- "sentence"
# Select the last five speeches
idx2 <- which(ObamaSpeech$idx > 97)
Speech2 <-as.data.frame(ObamaSpeech$contents[idx2])
names(Speech2) <- "sentence"
# Construct a corpus
# VectorSource specifies that the source is character vectors.
myCorpus1 <- Corpus(VectorSource(Speech1$sentence))
myCorpus1[[1]][1]
myCorpus2 <- Corpus(VectorSource(Speech2$sentence))
myCorpus2[[1]][1]
# Data preprocessing
# 1: to lower case
myCorpus1 <- tm_map(myCorpus1, content_transformer(tolower))
myCorpus1[[1]][1]
myCorpus2 <- tm_map(myCorpus2, content_transformer(tolower))
myCorpus2[[1]][1]
# 2: remove puntuations
myCorpus1 <- tm_map(myCorpus1, content_transformer(removePunctuation))
myCorpus1[[1]][1]
myCorpus2 <- tm_map(myCorpus2, content_transformer(removePunctuation))
myCorpus2[[1]][1]
# 3. remove numbers
myCorpus1 <- tm_map(myCorpus1, content_transformer(removeNumbers))
myCorpus1[[1]][1]
myCorpus2 <- tm_map(myCorpus2, content_transformer(removeNumbers))
myCorpus2[[1]][1]
# 4. remove stopwords (SMART stopwords list)
# Add "obama" to the stopwords list
myStopwords <- c(stopwords("SMART"), "obama")
myCorpus1 <- tm_map(myCorpus1, removeWords, myStopwords)
myCorpus1[[1]][1]
myCorpus2 <- tm_map(myCorpus2, removeWords, myStopwords)
myCorpus2[[1]][1]
# 5. Stemming
stemCorpus1 <- tm_map(myCorpus1, stemDocument)
myCorpus1[[1]][1]
stemCorpus2 <- tm_map(myCorpus2, stemDocument)
myCorpus2[[1]][1]
# Construct Term-Document Matrix
myTDM1 <- TermDocumentMatrix(stemCorpus1, control = list(minWordLength = 1))
myTDM2 <- TermDocumentMatrix(stemCorpus2, control = list(minWordLength = 1))
# Check the Term-Document Matrix
myTDM1
myTDM2
findFreqTerms(myTDM1, lowfreq=15)
findFreqTerms(myTDM2, lowfreq=15)
